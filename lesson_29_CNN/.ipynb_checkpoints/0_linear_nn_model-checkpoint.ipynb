{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn Keras \n",
    "source: \n",
    "https://www.learnopencv.com/deep-learning-using-keras-the-basics/\n",
    "\n",
    "The example of working model is linear NN with only FC layer and linear activation for regression for boston housing \n",
    "\n",
    "(190330)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Keras Layers\n",
    "\n",
    "Layers can be thought of as the building blocks of a Neural Network. They process the input data and produce different outputs, depending on the type of layer, which are then used by the layers which are connected to them. We will cover the details of every layer in future posts.\n",
    "Keras provides a number of core layers which include:\n",
    "- Dense layers, also called fully connected layer, since, each node in the input is connected to every node in the output,\n",
    "- Activation layer which includes activation functions like ReLU, tanh, sigmoid among others,\n",
    "- Dropout layer – used for regularization during training,\n",
    "- Flatten, Reshape, etc.\n",
    "\n",
    "Apart from these core layers, some important layers are\n",
    "- Convolution layers – used for performing convolution,\n",
    "- Pooling layers – used for down sampling,\n",
    "- Recurrent layers,\n",
    "- Locally-connected, normalization, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pg/_vz5kwcn2bxbjntlwb3gq_ph0000gp/T/ipykernel_18296/3760914084.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Keras Models\n",
    "Keras provides two ways to define a model:\n",
    "-Sequential, used for stacking up layers – Most commonly used.\n",
    "-Functional API, used for designing complex model architectures like models with multiple-outputs, shared layers etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For creating a Sequential model, we can either pass the list of layers as an argument to the constructor or add the layers sequentially using the model.add() function.\n",
    "For example, both the code snippets for creating a model with a single dense layer with 10 outputs are equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nFeatures = 100 # lets initialize with some value \n",
    "model = Sequential([Dense(10, input_shape=(nFeatures,)), \n",
    "                    Activation('linear') ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above gives the same result as  the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_shape=(nFeatures,)))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Configuring the training process\n",
    "\n",
    "Once the model is ready, we need to configure the learning process. This means\n",
    "- Specify an Optimizer which determines how the network weights are updated\n",
    "- Specify the type of cost function or loss function.\n",
    "- Specify the metrics you want to evaluate during training and testing.\n",
    "- Create the model graph using the backend.\n",
    "- Any other advanced configuration.\n",
    "\n",
    "This is done in Keras using the model.compile() function. The following code snippet shows the usage.\n",
    "Note: The mandatory parameters to be specified are the optimizer and the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers\n",
    "\n",
    "Keras provides a lot of optimizers to choose from, which include\n",
    "- Stochastic Gradient Descent ( SGD ),\n",
    "- Adam,\n",
    "- RMSprop,\n",
    "- AdaGrad,\n",
    "- AdaDelta, etc.\n",
    "\n",
    "RMSprop is a good choice of optimizer for most problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions\n",
    "\n",
    "In a supervised learning problem, we have to find the error between the actual values and the predicted value. There can be different metrics which can be used to evaluate this error. This metric is often called loss function or cost function or objective function. There can be more than one loss function depending on what you are doing with the error. In general, we use\n",
    "- binary-cross-entropy for a binary classification problem,\n",
    "- categorical-cross-entropy for a multi-class classification problem,\n",
    "- mean-squared-error for a regression problem and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Training\n",
    "Once the model is configured, we can start the training process. This can be done using the `model.fit()` function in Keras. The usage is described below.\n",
    "\n",
    "We just need to specify the training data, batch size and number of epochs. Keras automatically figures out how to pass the data iteratively to the optimizer for the number of epochs specified. The rest of the information was already given to the optimizer in the previous step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainFeatures, trainLabels, batch_size=4, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Evaluating the model\n",
    "\n",
    "Once the model is trained, we need to check the accuracy on unseen test data. \n",
    "This can be done in two ways in Keras.\n",
    "- model.evaluate() – It finds the loss and metrics specified in the model.compile() step. \n",
    " <br>It takes both the test data and labels as input and gives a quantitative measure of the accuracy.\n",
    " <br>It can also be used to perform cross-validation and further finetune the parameters to get the best model.\n",
    "- model.predict() – It finds the output for the given test data. It is useful for checking the outputs qualitatively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Example\n",
    "\n",
    "We will learn how to create a simple network with a single layer to perform linear regression. \n",
    "<br>We will use the [Boston Housing dataset](https://keras.io/datasets/) available in Keras as an example. \n",
    "<br>Samples contain 13 attributes of houses at different locations around the Boston suburbs in the late 1970s. <br>Targets are the median values of the houses at a location (in k$). \n",
    "<br>With the 13 features, we have to train the model which would predict the price of the house in the test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets review the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('X_train.shape= ',  X_train.shape)\n",
    "print ('Y_train.shape= ',  Y_train.shape)\n",
    "print ('X_test.shape= ',  X_test.shape)\n",
    "print ('Y_test.shape= ',  Y_test.shape)\n",
    "\n",
    "index = 1 \n",
    "print ('\\nReview sample. \\nX_train[{0}]:\\n{1},\\nY_train[{0}]= {2}'.format (index, X_train[index],Y_train[index] ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Training\n",
    "\n",
    "We use the Sequential model to create the network graph. \n",
    "<br>Then we add a Dense layer with the number of inputs equal to the number of features in the data and a single output. \n",
    "<br>Then we follow the workflow as explained in the previous section. We compile the model and train it using the fit command. \n",
    "<br>Finally, we use the model.summary() function to check the configuration of the model. \n",
    "<br>All keras datasets come with a load_data() function which returns tuples of training and testing data as shown in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.datasets import boston_housing\n",
    " \n",
    "# (X_train, Y_train), (X_test, Y_test) = boston_housing.load_data()\n",
    " \n",
    "nFeatures = X_train.shape[1]\n",
    "\n",
    "# use the Sequential model to create the network graph\n",
    "model = Sequential()\n",
    "\n",
    "# add a Dense layer with the number of inputs equal to the number of features in the data and a single output\n",
    "model.add(Dense(1, input_shape=(nFeatures,), activation='linear')) # guess you need to add the comma in case of single dimmension\n",
    "# e.g. # X_train shape: (1080, 64, 64, 3) -> input_shape = (64, 64, 3)\n",
    " \n",
    "# compile the model\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mse', 'mae'])\n",
    "\n",
    "# train it\n",
    "model.fit(X_train, Y_train, batch_size=4, epochs=1000)\n",
    " \n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of `model.summary()` is given below. \n",
    "\n",
    "It shows 14 parameters – 13 parameters for the weights and 1 for the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Inference\n",
    "\n",
    "After the model has been trained, we want to do inference on the test data. \n",
    "<br>We can find the loss on the test data using the `model.evaluate()` function. \n",
    "<br>We get the predictions on test data using the `model.predict()` function. \n",
    "<br>Here we compare the ground truth values with the predictions from our model for the first 5 test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test, verbose=True)\n",
    " \n",
    "Y_pred = model.predict(X_test)\n",
    " \n",
    "print (Y_test[:5])\n",
    "print (Y_pred[:5,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
